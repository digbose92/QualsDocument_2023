\chapter{Multimodal context-based large-scale semantic video understanding}
\section{Transition from static scenes to dynamic content}
\section{Semantic video understanding}
The need for understanding video semantics beyond actions and objects 

\subsection{Contextual signals as multi-modal streams:}
    \subsubsection{Visual scene context}
    \subsubsection{Auditory context}
    Background music + audio events + speech (vocalizations)
    \subsubsection{Language based context}
\section{Advertisements as medium}
\subsection{Challenges}
Mention three cases:
\begin{itemize}
\item Visual context changes sharply across shots but is tied together by an overall narrative (a diagram especially)
\item The visual narrative doesnâ€™t happen in isolation and is usually accompanied by a transition in musical tone (the contextual signal present in the background score/music sets the mood for the advertisement)
\item The verbal cues provide descriptions of the foreground activities, including character interactions and narrations about the overall theme/topic (Language driven foreground context representations)
\section{MM-AU dataset}
\subsection{Data sources}
\subsection{Human expert-driven annotations}
\subsection{Dataset statistics}
\section{Multimodal representative tasks}
\subsection{Topic categorization}
\subsection{Tone transition}
\subsection{Absence/Presence of socially relevant cues}
\section{Progressive multimodal fusion of contextual streams}
\section{Experiments and Results}
\subsection{Language-only reasoning}
\subsection{Unimodal vs Multimodal baselines}
\section{Limitations}
\section{Conclusions}
\end{itemize}




