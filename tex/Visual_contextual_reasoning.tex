\chapter{Visual scene contextual reasoning through multimodal guidance}
Add introduction to the chapter by linking previous chapter.
\section{Role of scene as contextual signal}
\section{Visual scene recognition}
\subsection{Challenges}
\subsection{Movies vs Natural scenes}
\section{Role of multi-modality:}
    \subsection{Language driven taxonomy curation}
    \subsection{Usage of vision-language models}
    \subsubsection{CLIP: Learning Transferable Visual Models From Natural Language Supervision}
    \subsection{MovieCLIP dataset}
    \subsubsection{CLIP-based visual tagging}
    \subsubsection{Analysis of CLIP tagging}
    \subsubsection{Quality estimation through human verification}
\section{Experiments and Results:}
\subsection{Experimental Setup}
\subsection{Visual scene recognition - Movies}
\subsection{Downstream tasks}
\subsubsection{Visual scene recognition - web videos}
\subsubsection{Multi label genre classification - movie trailers}
\subsubsection{Impact of MovieCLIP pretraining}
\section{Ethical implications}
\section{Conclusion}
 

    
\Blindtext[2]
